{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtD2cBZg42Ikfyv6kVJIo9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sausis20/Youtube-Trending-Scraper-and-EDA/blob/main/scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRaiS6gDzexf",
        "outputId": "a13dea87-d27f-4f3c-c743-85a0440dca9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/gdrive/My Drive/Colab Notebooks/YouTube Trending Scraper/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytC-zwmY_n3N",
        "outputId": "4db53c91-2970-4a0d-b441-722c7899de72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/YouTube Trending Scraper\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, sys, time, os, argparse\n",
        "\n",
        "# List of simple to collect features\n",
        "snippet_features = [\"title\",\n",
        "                    \"publishedAt\",\n",
        "                    \"channelId\",\n",
        "                    \"channelTitle\",\n",
        "                    \"categoryId\"]\n",
        "\n",
        "# Any characters to exclude, generally these are things that become problematic in CSV files\n",
        "unsafe_characters = ['\\n', '\"']\n",
        "\n",
        "# Used to identify columns, currently hardcoded order\n",
        "header = [\"video_id\"] + snippet_features + [\"trending_date\", \"tags\", \"view_count\", \"likes\", \"dislikes\",\n",
        "                                            \"comment_count\", \"thumbnail_link\", \"comments_disabled\",\n",
        "                                            \"ratings_disabled\", \"description\"]\n",
        "\n",
        "\n",
        "def setup(api_path, code_path):\n",
        "    with open(api_path, 'r') as file:\n",
        "        api_key = file.readline()\n",
        "\n",
        "    with open(code_path) as file:\n",
        "        country_codes = [x.rstrip() for x in file]\n",
        "\n",
        "    return(api_key, country_codes)\n",
        "\n",
        "def prepare_feature(feature):\n",
        "    # Removes any character from the unsafe characters list and surrounds the whole item in quotes\n",
        "    for ch in unsafe_characters:\n",
        "        feature = str(feature).replace(ch, \"\")\n",
        "    return f'\"{feature}\"'\n",
        "\n",
        "\n",
        "def api_request(page_token, country_code):\n",
        "    # Builds the URL and requests the JSON from it\n",
        "    request_url = f\"https://www.googleapis.com/youtube/v3/videos?part=id,statistics,snippet{page_token}chart=mostPopular&regionCode={country_code}&maxResults=50&key={api_key}\"\n",
        "    print(request_url)\n",
        "    request = requests.get(request_url)\n",
        "    if request.status_code == 429:\n",
        "        print(\"Temp-Banned due to excess requests, please wait and continue later\")\n",
        "        sys.exit()\n",
        "    return request.json()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_tags(tags_list):\n",
        "    # Takes a list of tags, prepares each tag and joins them into a string by the pipe character\n",
        "    return prepare_feature(\"|\".join(tags_list))\n",
        "\n",
        "\n",
        "def get_videos(items):\n",
        "    lines = []\n",
        "    for video in items:\n",
        "        comments_disabled = False\n",
        "        ratings_disabled = False\n",
        "\n",
        "        # We can assume something is wrong with the video if it has no statistics, often this means it has been deleted\n",
        "        # so we can just skip it\n",
        "        if \"statistics\" not in video:\n",
        "            continue\n",
        "\n",
        "        # A full explanation of all of these features can be found on the GitHub page for this project\n",
        "        video_id = prepare_feature(video['id'])\n",
        "\n",
        "        # Snippet and statistics are sub-dicts of video, containing the most useful info\n",
        "        snippet = video['snippet']\n",
        "        statistics = video['statistics']\n",
        "\n",
        "        # This list contains all of the features in snippet that are 1 deep and require no special processing\n",
        "        features = [prepare_feature(snippet.get(feature, \"\")) for feature in snippet_features]\n",
        "\n",
        "        # The following are special case features which require unique processing, or are not within the snippet dict\n",
        "        description = snippet.get(\"description\", \"\")\n",
        "        thumbnail_link = snippet.get(\"thumbnails\", dict()).get(\"default\", dict()).get(\"url\", \"\")\n",
        "        trending_date = time.strftime(\"%y.%d.%m\")\n",
        "        tags = get_tags(snippet.get(\"tags\", [\"[none]\"]))\n",
        "        view_count = statistics.get(\"viewCount\", 0)\n",
        "\n",
        "        # This may be unclear, essentially the way the API works is that if a video has comments or ratings disabled\n",
        "        # then it has no feature for it, thus if they don't exist in the statistics dict we know they are disabled\n",
        "        if 'likeCount' in statistics and 'dislikeCount' in statistics:\n",
        "            likes = statistics['likeCount']\n",
        "            dislikes = statistics['dislikeCount']\n",
        "        else:\n",
        "            ratings_disabled = True\n",
        "            likes = 0\n",
        "            dislikes = 0\n",
        "\n",
        "        if 'commentCount' in statistics:\n",
        "            comment_count = statistics['commentCount']\n",
        "        else:\n",
        "            comments_disabled = True\n",
        "            comment_count = 0\n",
        "\n",
        "        # Compiles all of the various bits of info into one consistently formatted line\n",
        "        line = [video_id] + features + [prepare_feature(x) for x in [trending_date, tags, view_count, likes, dislikes,\n",
        "                                                                       comment_count, thumbnail_link, comments_disabled,\n",
        "                                                                       ratings_disabled, description]]\n",
        "        lines.append(\",\".join(line))\n",
        "    return lines\n",
        "\n",
        "\n",
        "def get_pages(country_code):\n",
        "    country_data = []\n",
        "\n",
        "    # A page of data i.e. a list of videos and all needed data\n",
        "    video_data_page = api_request(\"&\", country_code)\n",
        "\n",
        "    # Get all of the items as a list and let get_videos return the needed features\n",
        "    items = video_data_page.get('items', [])\n",
        "    country_data += get_videos(items)\n",
        "\n",
        "    return country_data\n",
        "\n",
        "\n",
        "def write_to_file(country_code, country_data):\n",
        "\n",
        "    print(f\"Writing {country_code} data to file...\")\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    with open(f\"{output_dir}/{time.strftime('%y.%d.%m')}_{country_code}_videos.csv\", \"w+\", encoding='utf-8') as file:\n",
        "        for row in country_data:\n",
        "            file.write(f\"{row}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "def get_data():\n",
        "    for country_code in country_codes:\n",
        "        country_data = [\",\".join(header)] + get_pages(country_code)\n",
        "        write_to_file(country_code, country_data)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--key_path', help='Path to the file containing the api key, by default will use api_key.txt in the same directory', default='api_key.txt')\n",
        "    parser.add_argument('--country_code_path', help='Path to the file containing the list of country codes to scrape, by default will use country_codes.txt in the same directory', default='country_codes.txt')\n",
        "    parser.add_argument('--output_dir', help='Path to save the outputted files in', default='output/')\n",
        "\n",
        "    # To be used in command line interface\n",
        "    # args = parser.parse_args()\n",
        "\n",
        "    # To be used in Jupyter notebook\n",
        "    args = parser.parse_args(\"\")\n",
        "\n",
        "    output_dir = args.output_dir\n",
        "    api_key, country_codes = setup(args.key_path, args.country_code_path)\n",
        "\n",
        "    get_data()\n"
      ],
      "metadata": {
        "id": "unP-BGne5_dD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8aeede6-ff10-414d-c70e-4cfa4c7d7972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.googleapis.com/youtube/v3/videos?part=id,statistics,snippet&chart=mostPopular&regionCode=LT&maxResults=50&key=AIzaSyBpZTqEAh0ofkGd8kGz35k71evMYFDztFY\n",
            "Writing LT data to file...\n",
            "https://www.googleapis.com/youtube/v3/videos?part=id,statistics,snippet&chart=mostPopular&regionCode=LV&maxResults=50&key=AIzaSyBpZTqEAh0ofkGd8kGz35k71evMYFDztFY\n",
            "Writing LV data to file...\n",
            "https://www.googleapis.com/youtube/v3/videos?part=id,statistics,snippet&chart=mostPopular&regionCode=EE&maxResults=50&key=AIzaSyBpZTqEAh0ofkGd8kGz35k71evMYFDztFY\n",
            "Writing EE data to file...\n",
            "https://www.googleapis.com/youtube/v3/videos?part=id,statistics,snippet&chart=mostPopular&regionCode=PL&maxResults=50&key=AIzaSyBpZTqEAh0ofkGd8kGz35k71evMYFDztFY\n",
            "Writing PL data to file...\n",
            "https://www.googleapis.com/youtube/v3/videos?part=id,statistics,snippet&chart=mostPopular&regionCode=FI&maxResults=50&key=AIzaSyBpZTqEAh0ofkGd8kGz35k71evMYFDztFY\n",
            "Writing FI data to file...\n",
            "https://www.googleapis.com/youtube/v3/videos?part=id,statistics,snippet&chart=mostPopular&regionCode=SE&maxResults=50&key=AIzaSyBpZTqEAh0ofkGd8kGz35k71evMYFDztFY\n",
            "Writing SE data to file...\n",
            "https://www.googleapis.com/youtube/v3/videos?part=id,statistics,snippet&chart=mostPopular&regionCode=NO&maxResults=50&key=AIzaSyBpZTqEAh0ofkGd8kGz35k71evMYFDztFY\n",
            "Writing NO data to file...\n",
            "https://www.googleapis.com/youtube/v3/videos?part=id,statistics,snippet&chart=mostPopular&regionCode=US&maxResults=50&key=AIzaSyBpZTqEAh0ofkGd8kGz35k71evMYFDztFY\n",
            "Writing US data to file...\n",
            "https://www.googleapis.com/youtube/v3/videos?part=id,statistics,snippet&chart=mostPopular&regionCode=CA&maxResults=50&key=AIzaSyBpZTqEAh0ofkGd8kGz35k71evMYFDztFY\n",
            "Writing CA data to file...\n",
            "https://www.googleapis.com/youtube/v3/videos?part=id,statistics,snippet&chart=mostPopular&regionCode=GB&maxResults=50&key=AIzaSyBpZTqEAh0ofkGd8kGz35k71evMYFDztFY\n",
            "Writing GB data to file...\n",
            "https://www.googleapis.com/youtube/v3/videos?part=id,statistics,snippet&chart=mostPopular&regionCode=DE&maxResults=50&key=AIzaSyBpZTqEAh0ofkGd8kGz35k71evMYFDztFY\n",
            "Writing DE data to file...\n",
            "https://www.googleapis.com/youtube/v3/videos?part=id,statistics,snippet&chart=mostPopular&regionCode=FR&maxResults=50&key=AIzaSyBpZTqEAh0ofkGd8kGz35k71evMYFDztFY\n",
            "Writing FR data to file...\n"
          ]
        }
      ]
    }
  ]
}